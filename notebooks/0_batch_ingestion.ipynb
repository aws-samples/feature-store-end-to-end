{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7b5379",
   "metadata": {},
   "source": [
    "# Batch Ingestion\n",
    "This notebook reads the raw data from an S3 bucket, transforms it for ingestion into SageMaker Feature Store and then ingests it into an offline+online Feature Store. Refer [Official SageMaker FeatureStore documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html) and [Python SDK](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_featurestore.html).\n",
    "\n",
    "We create two feature groups in this notebook:\n",
    "1. An offline+online feature group for customer inputs that is used for ML model training.\n",
    "2. An offline+online feature group for the destinations features, this is used both for ML model training and real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdb6bc",
   "metadata": {},
   "source": [
    "**Note:** Please set kernel to `conda_python3` for this notebook and select instance to `ml.t3.2xlarge` as part of user inputs to the CloudFormation template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32816ed",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd2b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f84c0a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/feature-store-end-to-end/utils\n"
     ]
    }
   ],
   "source": [
    "# import from a different path\n",
    "sys.path.insert(0, '../utils')\n",
    "path = Path(os.path.abspath(os.getcwd()))\n",
    "package_dir = f'{str(path.parent)}/utils'\n",
    "print(package_dir)\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da8f3e",
   "metadata": {},
   "source": [
    "## Setup Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45521d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:31:40,803,<ipython-input-3-e08248e9535e>,<module>,3,INFO,p27363,Using SageMaker version: 2.86.2\n",
      "2022-07-22 20:31:40,804,<ipython-input-3-e08248e9535e>,<module>,4,INFO,p27363,Using Pandas version: 1.1.5\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('__name__')\n",
    "logging.basicConfig(format=\"%(asctime)s,%(filename)s,%(funcName)s,%(lineno)s,%(levelname)s,p%(process)s,%(message)s\", level=logging.INFO)       \n",
    "logger.info(f'Using SageMaker version: {sagemaker.__version__}')\n",
    "logger.info(f'Using Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f17fa",
   "metadata": {},
   "source": [
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39c996e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "STACK_NAME = \"expedia-feature-store-demo-v2\"\n",
    "\n",
    "# number of worker processes to use for batch ingesting data into feature store\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "# number of principal components to keep for the destinations dataset\n",
    "PC_TO_KEEP = 3\n",
    "\n",
    "# this is a sagemaker limit\n",
    "MAX_ALLOWED_FEATURE_GROUPS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e3e45",
   "metadata": {},
   "source": [
    "## Setup Config Variables\n",
    "Read the config variables used by this notebook from the cloud formation outputs and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b66dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "2022-07-22 20:31:45,829,<ipython-input-5-f06a6a5b0cb4>,<module>,6,INFO,p27363,data_bucket_name=expedia-customer-behavior-data-eb4dbb00,\n",
      "athena_query_results_bucket_name=athena-query-results-eb4dbb00,\n",
      "feature_store_bucket_name=expedia-feature-store-offline-eb4dbb00\n"
     ]
    }
   ],
   "source": [
    "# read output variables from cloud formation stack, these will be used as parameters throughout\n",
    "# the code\n",
    "data_bucket_name = utils.get_cfn_stack_outputs(STACK_NAME, 'DataBucketName')\n",
    "athena_query_results_bucket_name = utils.get_cfn_stack_outputs(STACK_NAME, 'AthenaQueryResultsBucketName')\n",
    "feature_store_bucket_name = utils.get_cfn_stack_outputs(STACK_NAME, 'FeatureStoreBucketName')\n",
    "logger.info(f\"data_bucket_name={data_bucket_name},\\nathena_query_results_bucket_name={athena_query_results_bucket_name},\\nfeature_store_bucket_name={feature_store_bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21d96e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:31:51,280,<ipython-input-6-78641fb40f60>,<module>,25,INFO,p27363,customer_inputs_fg_name=expedia-customer-inputs-2022-7-22-20-31,\n",
      "destinations_fg_name=expedia-destinations-2022-7-22-20-31\n",
      "destination_features_fname=destinations.csv\n",
      "always_recreate_fg=False,\n",
      "raw_data_dir=raw_data,\n",
      "training_dataset_fname=train.csv,\n",
      "test_dataset_fname=test.csv, app_name=hotel_cluster_prediction\n"
     ]
    }
   ],
   "source": [
    "# read params from cloud formation stack. The cloud formation stack provided a convenient\n",
    "# way to provide configuration parameters for a notebook workflow without having to use\n",
    "# parameter store or other services for providing config.\n",
    "customer_inputs_fg_name = utils.get_cfn_stack_parameters(STACK_NAME, 'CustomerInputFeatureGroupName')\n",
    "destinations_fg_name = utils.get_cfn_stack_parameters(STACK_NAME, 'DestinationsFeatureGroupName')\n",
    "app_name = utils.get_cfn_stack_parameters(STACK_NAME, 'AppName')\n",
    "\n",
    "always_recreate_fg = utils.get_cfn_stack_parameters(STACK_NAME, 'AlwaysRecreateFeatureGroup')\n",
    "always_recreate_fg = True if always_recreate_fg == \"true\" else False\n",
    "\n",
    "raw_data_dir = utils.get_cfn_stack_parameters(STACK_NAME, 'RawDataDir')\n",
    "training_dataset_fname = utils.get_cfn_stack_parameters(STACK_NAME, 'TrainingDatasetFileName')\n",
    "test_dataset_fname = utils.get_cfn_stack_parameters(STACK_NAME, 'TestDatasetFileName')\n",
    "destination_features_fname = utils.get_cfn_stack_parameters(STACK_NAME, 'DestinationFeaturesFileName')\n",
    "\n",
    "# If an existing feature group by the same name is not going to be deleted then\n",
    "# append a unique suffix to the feature group name to create a new unique feature group name\n",
    "if always_recreate_fg is False:\n",
    "    dttm = datetime.now()\n",
    "    suffix = f\"{dttm.year}-{dttm.month}-{dttm.day}-{dttm.hour}-{dttm.minute}\"\n",
    "    customer_inputs_fg_name = f\"{customer_inputs_fg_name}-{suffix}\"\n",
    "    destinations_fg_name = f\"{destinations_fg_name}-{suffix}\"\n",
    "\n",
    "# log all params debugging help\n",
    "logger.info(f\"customer_inputs_fg_name={customer_inputs_fg_name},\\ndestinations_fg_name={destinations_fg_name}\\ndestination_features_fname={destination_features_fname}\\n\"\n",
    "            f\"always_recreate_fg={always_recreate_fg},\\n\"\n",
    "            f\"raw_data_dir={raw_data_dir},\\ntraining_dataset_fname={training_dataset_fname},\\n\"\n",
    "            f\"test_dataset_fname={test_dataset_fname}, app_name={app_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ffa49",
   "metadata": {},
   "source": [
    "## Read raw data from S3 bucket\n",
    "The raw data exists in an S3 bucket. Note that the data upload to the S3 bucket in the raw data directory (typicall raw_data) needs to be done manually prior to running this step. The data is read directly using the Pandas read_csv method. In another version of this code, Pandas will be replaced with Pyspark.\n",
    "\n",
    "We read two datasets here:\n",
    "1. The customer inputs datasets from the train.csv file that represents customers looking up hotels via the Expedia website.\n",
    "2. The destination features dataset from destinations.csv that represents embeddings for each destination, this will be joined with the customer input dataset at the time of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e792fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:32:03,589,api.py,from_bytes,356,INFO,p27363,ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      "2022-07-22 20:32:03,590,api.py,from_bytes,367,INFO,p27363,ascii should target any language(s) of ['Latin Based']\n",
      "2022-07-22 20:32:03,594,api.py,from_bytes,385,INFO,p27363,We detected language [('English', 1.0), ('Indonesian', 1.0), ('Simple English', 1.0)] using ascii\n",
      "2022-07-22 20:32:03,594,api.py,from_bytes,419,INFO,p27363,ascii is most likely the one. Stopping the process.\n",
      "2022-07-22 20:32:03,602,api.py,from_bytes,356,INFO,p27363,ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      "2022-07-22 20:32:03,603,api.py,from_bytes,367,INFO,p27363,ascii should target any language(s) of ['Latin Based']\n",
      "2022-07-22 20:32:03,608,api.py,from_bytes,385,INFO,p27363,We detected language [('German', 0.8333), ('Hungarian', 0.8333), ('Slovak', 0.8333), ('English', 0.75), ('Dutch', 0.75), ('Italian', 0.75), ('Swedish', 0.75), ('Norwegian', 0.75), ('Czech', 0.75), ('Indonesian', 0.75), ('Danish', 0.75), ('Polish', 0.6667), ('Finnish', 0.6667), ('Slovene', 0.6667), ('Turkish', 0.5833), ('Vietnamese', 0.5), ('Lithuanian', 0.5)] using ascii\n",
      "2022-07-22 20:32:03,609,api.py,from_bytes,419,INFO,p27363,ascii is most likely the one. Stopping the process.\n",
      "2022-07-22 20:32:03,623,api.py,from_bytes,356,INFO,p27363,ascii passed initial chaos probing. Mean measured chaos is 0.000000 %\n",
      "2022-07-22 20:32:03,623,api.py,from_bytes,367,INFO,p27363,ascii should target any language(s) of ['Latin Based']\n",
      "2022-07-22 20:32:03,627,api.py,from_bytes,385,INFO,p27363,We detected language [('English', 1.0), ('Indonesian', 1.0), ('Simple English', 1.0)] using ascii\n",
      "2022-07-22 20:32:03,627,api.py,from_bytes,419,INFO,p27363,ascii is most likely the one. Stopping the process.\n",
      "2022-07-22 20:35:49,922,<ipython-input-7-21068048b93d>,<module>,4,INFO,p27363,shape of the dataframe read from s3a://expedia-customer-behavior-data-eb4dbb00/raw_data/train.csv is (37670293, 24)\n",
      "2022-07-22 20:35:55,652,utils.py,_init_num_threads,157,INFO,p27363,NumExpr defaulting to 8 threads.\n",
      "2022-07-22 20:35:58,593,<ipython-input-7-21068048b93d>,<module>,8,INFO,p27363,shape of the dataframe after dropna is (24117894, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>is_booking</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-11 07:46:59</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-11 08:22:12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-11 08:24:33</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-09 18:05:16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>442</td>\n",
       "      <td>35390</td>\n",
       "      <td>913.1932</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1457</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-09 18:08:18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>442</td>\n",
       "      <td>35390</td>\n",
       "      <td>913.6259</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1457</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time  site_name  posa_continent  user_location_country  \\\n",
       "0  2014-08-11 07:46:59          2               3                     66   \n",
       "1  2014-08-11 08:22:12          2               3                     66   \n",
       "2  2014-08-11 08:24:33          2               3                     66   \n",
       "3  2014-08-09 18:05:16          2               3                     66   \n",
       "4  2014-08-09 18:08:18          2               3                     66   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance  \\\n",
       "0                   348               48862                  2234.2641   \n",
       "1                   348               48862                  2234.2641   \n",
       "2                   348               48862                  2234.2641   \n",
       "3                   442               35390                   913.1932   \n",
       "4                   442               35390                   913.6259   \n",
       "\n",
       "   user_id  is_mobile  is_package  ...  srch_children_cnt srch_rm_cnt  \\\n",
       "0       12          0           1  ...                  0           1   \n",
       "1       12          0           1  ...                  0           1   \n",
       "2       12          0           0  ...                  0           1   \n",
       "3       93          0           0  ...                  0           1   \n",
       "4       93          0           0  ...                  0           1   \n",
       "\n",
       "  srch_destination_id  srch_destination_type_id  is_booking  cnt  \\\n",
       "0                8250                         1           0    3   \n",
       "1                8250                         1           1    1   \n",
       "2                8250                         1           0    1   \n",
       "3               14984                         1           0    1   \n",
       "4               14984                         1           0    1   \n",
       "\n",
       "   hotel_continent  hotel_country  hotel_market  hotel_cluster  \n",
       "0                2             50           628              1  \n",
       "1                2             50           628              1  \n",
       "2                2             50           628              1  \n",
       "3                2             50          1457             80  \n",
       "4                2             50          1457             21  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data from the bucket in a pandas dataframe, this will be ingested in the feature store\n",
    "s3a_uri = f\"s3a://{data_bucket_name}/{raw_data_dir}/{training_dataset_fname}\"\n",
    "df = pd.read_csv(s3a_uri)\n",
    "logger.info(f\"shape of the dataframe read from {s3a_uri} is {df.shape}\")\n",
    "\n",
    "# drop rows with NA\n",
    "df_customer_inputs = df.dropna()\n",
    "logger.info(f\"shape of the dataframe after dropna is {df_customer_inputs.shape}\")\n",
    "display(df_customer_inputs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e901c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:36:04,926,<ipython-input-8-852fe5e78f44>,<module>,4,INFO,p27363,shape of the dataframe read from s3a://expedia-customer-behavior-data-eb4dbb00/raw_data/destinations.csv is (62106, 150)\n",
      "2022-07-22 20:36:04,971,<ipython-input-8-852fe5e78f44>,<module>,8,INFO,p27363,shape of the dataframe after dropna is (62106, 150)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>...</th>\n",
       "      <th>d140</th>\n",
       "      <th>d141</th>\n",
       "      <th>d142</th>\n",
       "      <th>d143</th>\n",
       "      <th>d144</th>\n",
       "      <th>d145</th>\n",
       "      <th>d146</th>\n",
       "      <th>d147</th>\n",
       "      <th>d148</th>\n",
       "      <th>d149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.082564</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.031597</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.183490</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.189562</td>\n",
       "      <td>-2.105819</td>\n",
       "      <td>-2.075407</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.118483</td>\n",
       "      <td>-2.140393</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.196379</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.192009</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.057548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.115485</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.161081</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.189562</td>\n",
       "      <td>-2.187783</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.171153</td>\n",
       "      <td>-2.152303</td>\n",
       "      <td>-2.056618</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.145911</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.187356</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.191779</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.185161</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.188037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_destination_id        d1        d2        d3        d4        d5  \\\n",
       "0                    0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657   \n",
       "1                    1 -2.181690 -2.181690 -2.181690 -2.082564 -2.181690   \n",
       "2                    2 -2.183490 -2.224164 -2.224164 -2.189562 -2.105819   \n",
       "3                    3 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409   \n",
       "4                    4 -2.189562 -2.187783 -2.194008 -2.171153 -2.152303   \n",
       "\n",
       "         d6        d7        d8        d9  ...      d140      d141      d142  \\\n",
       "0 -1.897627 -2.198657 -2.198657 -1.897627  ... -2.198657 -2.198657 -2.198657   \n",
       "1 -2.165028 -2.181690 -2.181690 -2.031597  ... -2.165028 -2.181690 -2.165028   \n",
       "2 -2.075407 -2.224164 -2.118483 -2.140393  ... -2.224164 -2.224164 -2.196379   \n",
       "3 -2.115485 -2.177409 -2.177409 -2.177409  ... -2.161081 -2.177409 -2.177409   \n",
       "4 -2.056618 -2.194008 -2.194008 -2.145911  ... -2.187356 -2.194008 -2.191779   \n",
       "\n",
       "       d143      d144      d145      d146      d147      d148      d149  \n",
       "0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657  \n",
       "1 -2.181690 -2.181690 -2.165028 -2.181690 -2.181690 -2.181690 -2.181690  \n",
       "2 -2.224164 -2.192009 -2.224164 -2.224164 -2.224164 -2.224164 -2.057548  \n",
       "3 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409  \n",
       "4 -2.194008 -2.194008 -2.185161 -2.194008 -2.194008 -2.194008 -2.188037  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data from the bucket in a pandas dataframe, this will be ingested in the feature store\n",
    "s3a_uri = f\"s3a://{data_bucket_name}/{raw_data_dir}/{destination_features_fname}\"\n",
    "df_destinations = pd.read_csv(s3a_uri)\n",
    "logger.info(f\"shape of the dataframe read from {s3a_uri} is {df_destinations.shape}\")\n",
    "\n",
    "# drop rows with NA\n",
    "df_destinations = df_destinations.dropna()\n",
    "logger.info(f\"shape of the dataframe after dropna is {df_destinations.shape}\")\n",
    "display(df_destinations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd92ec",
   "metadata": {},
   "source": [
    "## Data Transformation for Ingesting Into Feature Store\n",
    "Before this data can be ingested into the SageMaker FeatureStore, certain transformations need to be done.\n",
    "\n",
    "1. The date_time field which will be used as \"Event Time\" need to be converted to the ISO-8601 format i.e. YYYY-MM-DDTHH:MM:SSZ.\n",
    "2. The user_id field which will be used for \"Record Identifier\" needs to be converted to string.\n",
    "3. All \"object\" type fields need to be converted to string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c97052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# convert to datetime first\n",
    "df_customer_inputs.date_time = pd.to_datetime(df_customer_inputs.date_time)\n",
    "\n",
    "# the above returns (for example) 2015-09-03 17:09:54, change this to 2015-09-03T17:09:54Z\n",
    "# The dataset documentation does not mention the timezone of the date_time so will just assume it to be UTC.\n",
    "df_customer_inputs.date_time = df_customer_inputs.date_time.map(lambda x: x.isoformat() + 'Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5242ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user_id to string\n",
    "df_customer_inputs.user_id = df_customer_inputs.user_id.astype(\"string\")\n",
    "\n",
    "# destination id as well since this is going to be used as a key in the feature group for the destinations data\n",
    "# and the feature group record identifier can only be a string, BUT this is not the destinations table this is\n",
    "# the customer inputs table...so what gives..well, the customer inputs and destinations would be joined at the\n",
    "# time of model training and instead of doing a cast there, let's just do it here.\n",
    "df_customer_inputs.srch_destination_id = df_customer_inputs.srch_destination_id.astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a21c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:39:01,172,<ipython-input-11-85ff158cbdf4>,<module>,4,INFO,p27363,after removing all is_booking != 1 rows, shape of dataframe (1985514, 24)\n"
     ]
    }
   ],
   "source": [
    "# only keep rows where is_booking == 1 because we are only concerned with events when the user actually booked a hotel and that is also what the test data contains. \n",
    "if \"is_booking\" in df_customer_inputs.columns:\n",
    "    df_customer_inputs = df_customer_inputs[df_customer_inputs.is_booking == 1]\n",
    "    logger.info(f\"after removing all is_booking != 1 rows, shape of dataframe {df_customer_inputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab18fa69",
   "metadata": {},
   "source": [
    "### Create derived features\n",
    "These features can then be stored in the Feature Store and be used for training the model. This is the advantage of having a feature store, these derived features would now be available ready to use when we want to train an ML model, any model whether it is the one being created in this repo or for a new future use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2491b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create derived features\n",
    "\n",
    "# duration of the trip for which the hotel booking is needed seems to be intituively important\n",
    "df_customer_inputs['duration'] = (pd.to_datetime(df_customer_inputs.srch_co, errors='coerce') - pd.to_datetime(df_customer_inputs.srch_ci, errors='coerce')).astype('timedelta64[D]')\n",
    "\n",
    "# how far is the trip from the time when the user was looking up the Expedia website\n",
    "df_customer_inputs['days_to_trip'] = (pd.to_datetime(df.srch_ci, errors='coerce') - pd.to_datetime(df_customer_inputs.date_time, errors='coerce').dt.tz_localize(None)).astype('timedelta64[D]')\n",
    "\n",
    "# is the start or end of the trip on a weekend?\n",
    "df_customer_inputs['start_of_trip_weekend'] = (pd.to_datetime(df_customer_inputs.srch_ci, errors='coerce').dt.weekday >= 5).astype(int)\n",
    "df_customer_inputs['end_of_trip_weekend'] = (pd.to_datetime(df_customer_inputs.srch_co, errors='coerce').dt.weekday >= 5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dd45abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert any \"object\" type columns to string\n",
    "utils.cast_object_to_string(df_customer_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb3b0301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>is_booking</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_to_trip</th>\n",
       "      <th>start_of_trip_weekend</th>\n",
       "      <th>end_of_trip_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-11T08:22:12Z</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2014-01-03T16:30:17Z</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>462</td>\n",
       "      <td>41898</td>\n",
       "      <td>2454.8588</td>\n",
       "      <td>1482</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>680</td>\n",
       "      <td>95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2014-01-03T16:44:56Z</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>462</td>\n",
       "      <td>41898</td>\n",
       "      <td>2454.8588</td>\n",
       "      <td>1482</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>680</td>\n",
       "      <td>95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2014-01-03T17:11:36Z</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>462</td>\n",
       "      <td>41898</td>\n",
       "      <td>2454.8588</td>\n",
       "      <td>1482</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>680</td>\n",
       "      <td>95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2014-10-29T14:32:19Z</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>174</td>\n",
       "      <td>40365</td>\n",
       "      <td>8456.8294</td>\n",
       "      <td>1713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time  site_name  posa_continent  user_location_country  \\\n",
       "1    2014-08-11T08:22:12Z          2               3                     66   \n",
       "79   2014-01-03T16:30:17Z          2               3                     66   \n",
       "81   2014-01-03T16:44:56Z          2               3                     66   \n",
       "83   2014-01-03T17:11:36Z          2               3                     66   \n",
       "128  2014-10-29T14:32:19Z          2               3                     66   \n",
       "\n",
       "     user_location_region  user_location_city  orig_destination_distance  \\\n",
       "1                     348               48862                  2234.2641   \n",
       "79                    462               41898                  2454.8588   \n",
       "81                    462               41898                  2454.8588   \n",
       "83                    462               41898                  2454.8588   \n",
       "128                   174               40365                  8456.8294   \n",
       "\n",
       "    user_id  is_mobile  is_package  ...  is_booking cnt hotel_continent  \\\n",
       "1        12          0           1  ...           1   1               2   \n",
       "79     1482          0           1  ...           1   1               2   \n",
       "81     1482          0           1  ...           1   1               2   \n",
       "83     1482          0           1  ...           1   1               2   \n",
       "128    1713          0           0  ...           1   1               3   \n",
       "\n",
       "     hotel_country  hotel_market  hotel_cluster duration  days_to_trip  \\\n",
       "1               50           628              1      4.0          17.0   \n",
       "79              50           680             95      5.0          49.0   \n",
       "81              50           680             95      5.0          49.0   \n",
       "83              50           680             95      3.0          51.0   \n",
       "128              5            89             38      1.0          12.0   \n",
       "\n",
       "     start_of_trip_weekend  end_of_trip_weekend  \n",
       "1                        0                    0  \n",
       "79                       1                    0  \n",
       "81                       1                    0  \n",
       "83                       0                    0  \n",
       "128                      0                    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customer_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dda5d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:39:20,361,<ipython-input-15-7c7d626332f7>,<module>,4,INFO,p27363,there are 596662 user_ids in the dataset\n",
      "2022-07-22 20:39:20,940,<ipython-input-15-7c7d626332f7>,<module>,12,INFO,p27363,after filtering dataframe to keep 1.0% of all user_ids, dataframe shape is (19658, 28)\n"
     ]
    }
   ],
   "source": [
    "# reduce the size of the dataset to make it more manageable for this demo\n",
    "unique_user_id = list(df_customer_inputs.user_id.unique())\n",
    "num_unique_user_ids = len(unique_user_id)\n",
    "logger.info(f\"there are {len(unique_user_id)} user_ids in the dataset\")\n",
    "\n",
    "# select 1% of the unique users\n",
    "import random\n",
    "FRACTION_OF_USER_IDS_TO_KEEP = 0.01\n",
    "if FRACTION_OF_USER_IDS_TO_KEEP != 1:\n",
    "    fraction_of_unique_user_ids = random.sample(unique_user_id, int(num_unique_user_ids*FRACTION_OF_USER_IDS_TO_KEEP))\n",
    "    df_customer_inputs = df_customer_inputs[df_customer_inputs.user_id.isin(fraction_of_unique_user_ids)]\n",
    "    logger.info(f\"after filtering dataframe to keep {100*FRACTION_OF_USER_IDS_TO_KEEP}% of all user_ids, dataframe shape is {df_customer_inputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9559d7f",
   "metadata": {},
   "source": [
    "## Initialize SageMaker and FeatureStore Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "626a0a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n",
      "2022-07-22 20:39:21,344,<ipython-input-16-f1ccef0ce271>,<module>,10,INFO,p27363,role=arn:aws:iam::015469603702:role/expedia-feature-store-demo-v2-SageMakerRole-YGFIDVSCM9DT, region=us-east-1, account_id=015469603702\n"
     ]
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\n",
    "\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "logger.info(f\"role={role}, region={region}, account_id={account_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7ff7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature store session object\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f0bdd2",
   "metadata": {},
   "source": [
    "## Cleanup Existing FeatureGroup (if needed)\n",
    "To allow running this notebook multiple time and not create a new feature group on every run we have a config parameter which controls whether or not to delete existing feature group by the same name. If the always recreate feature group param is set to false then a new feature group is created by suffixing the current datetime to the configured feature group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ed42c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:54:10,744,<ipython-input-43-39696254ed5d>,<module>,6,INFO,p27363,there are 0 feature groups\n",
      "2022-07-22 20:54:10,745,<ipython-input-43-39696254ed5d>,<module>,7,INFO,p27363,{'FeatureGroupSummaries': [], 'ResponseMetadata': {'RequestId': '85a4da63-a99f-4fde-8377-ab961ef9cff0', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '85a4da63-a99f-4fde-8377-ab961ef9cff0', 'content-type': 'application/x-amz-json-1.1', 'content-length': '28', 'date': 'Fri, 22 Jul 2022 20:54:10 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# get a list of feature groups\n",
    "fg_list = sagemaker_client.list_feature_groups()\n",
    "num_feature_groups = len(fg_list['FeatureGroupSummaries'])\n",
    "if num_feature_groups == MAX_ALLOWED_FEATURE_GROUPS:\n",
    "    logger.error(f\"number fo already existing feature groups is {num_feature_groups}, no more feature groups can be created, delete some feature groups and try again\")\n",
    "logger.info(f\"there are {num_feature_groups} feature groups\")\n",
    "logger.info(fg_list)\n",
    "# if the feature group list is not empty and always recreate feature groups is set to True then delete existing feature group\n",
    "if always_recreate_fg is True and len(fg_list['FeatureGroupSummaries']) > 0:\n",
    "    logger.warning(f\"always_recreate_fg is True, going to delete feature groups\")\n",
    "    _ = [sagemaker_client.delete_feature_group(FeatureGroupName=fg['FeatureGroupName']) for fg in fg_list['FeatureGroupSummaries'] if fg['FeatureGroupName'] in [customer_inputs_fg_name, destinations_fg_name]]\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223527f9",
   "metadata": {},
   "source": [
    "# Create Feature Group\n",
    "Create a Feature Group and then set the schema from the feature group using the existing dataframe that contains the transformed data (already amenable for ingestion into feature store.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c78f0c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='date_time', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='site_name', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='posa_continent', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='user_location_country', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='user_location_region', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='user_location_city', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='orig_destination_distance', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='user_id', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='is_mobile', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='is_package', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='channel', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='srch_ci', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='srch_co', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='srch_adults_cnt', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='srch_children_cnt', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='srch_rm_cnt', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='srch_destination_id', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='srch_destination_type_id', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='is_booking', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='cnt', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='hotel_continent', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='hotel_country', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='hotel_market', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='hotel_cluster', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='duration', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='days_to_trip', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='start_of_trip_weekend', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>),\n",
       " FeatureDefinition(feature_name='end_of_trip_weekend', feature_type=<FeatureTypeEnum.INTEGRAL: 'Integral'>)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group = FeatureGroup(name=customer_inputs_fg_name, sagemaker_session=feature_store_session)\n",
    "feature_group.load_feature_definitions(data_frame=df_customer_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842548e7",
   "metadata": {},
   "source": [
    "This is the actual feature group creation step. Note that we usually always want to create an **online + offline feature store**. Online because we want to use it for real time predictions and offline because we want to use it for model training. While in this particular use case, a separate test dataset is provided so an online datastore is much more relevant for the tedt dataset rather than the training dataset, neverthless an offline+online datastore here does not hurt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3a0a2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:015469603702:feature-group/expedia-customer-inputs-2022-7-22-20-31',\n",
       " 'ResponseMetadata': {'RequestId': '774f9842-f61c-4fec-9684-9917cb9f4cbd',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '774f9842-f61c-4fec-9684-9917cb9f4cbd',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '116',\n",
       "   'date': 'Fri, 22 Jul 2022 20:54:14 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.create(\n",
    "    s3_uri=f\"s3://{feature_store_bucket_name}/{customer_inputs_fg_name}\",\n",
    "    record_identifier_name=\"user_id\",\n",
    "    event_time_feature_name=\"date_time\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True,\n",
    "    tags=[{'Key':'project','Value':'expedia-feature-store-demo'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abc8ee6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:54:15,017,utils.py,check_feature_group_status,99,INFO,p27363,Waiting for Feature Group to be Created\n",
      "2022-07-22 20:54:20,080,utils.py,check_feature_group_status,99,INFO,p27363,Waiting for Feature Group to be Created\n",
      "2022-07-22 20:54:25,189,utils.py,check_feature_group_status,99,INFO,p27363,Waiting for Feature Group to be Created\n",
      "2022-07-22 20:54:30,271,utils.py,check_feature_group_status,99,INFO,p27363,Waiting for Feature Group to be Created\n",
      "2022-07-22 20:54:35,345,utils.py,check_feature_group_status,102,INFO,p27363,FeatureGroup expedia-customer-inputs-2022-7-22-20-31 successfully created.\n"
     ]
    }
   ],
   "source": [
    "utils.check_feature_group_status(feature_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1f2c4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:54:35,353,<ipython-input-47-7dc3a283fdae>,<module>,3,INFO,p27363,about to begin ingestion of data into feature store, max_workers=8\n",
      "2022-07-22 20:54:38,067,feature_group.py,_ingest_single_batch,211,INFO,p9845,Started ingesting index 7374 to 9832\n",
      "2022-07-22 20:54:38,094,feature_group.py,_ingest_single_batch,211,INFO,p9845,Started ingesting index 12290 to 14748\n",
      "2022-07-22 20:54:38,111,feature_group.py,_ingest_single_batch,211,INFO,p9845,Started ingesting index 9832 to 12290\n",
      "2022-07-22 20:54:38,124,feature_group.py,_ingest_single_batch,211,INFO,p9845,Started ingesting index 2458 to 4916\n",
      "2022-07-22 20:54:38,160,feature_group.py,_ingest_single_batch,211,INFO,p9845,Started ingesting index 17206 to 19658\n",
      "2022-07-22 20:54:38,162,feature_group.py,_ingest_single_batch,211,INFO,p9845,Started ingesting index 14748 to 17206\n",
      "2022-07-22 20:54:38,178,feature_group.py,_ingest_single_batch,211,INFO,p9845,Started ingesting index 4916 to 7374\n",
      "2022-07-22 20:54:38,197,feature_group.py,_ingest_single_batch,211,INFO,p9845,Started ingesting index 0 to 2458\n",
      "2022-07-22 20:55:24,744,feature_group.py,_run_multi_threaded,366,INFO,p9845,Successfully ingested row 0 to 2458\n",
      "2022-07-22 20:55:24,825,feature_group.py,_run_multi_threaded,366,INFO,p9845,Successfully ingested row 7374 to 9832\n",
      "2022-07-22 20:55:25,453,feature_group.py,_run_multi_threaded,366,INFO,p9845,Successfully ingested row 4916 to 7374\n",
      "2022-07-22 20:55:25,900,feature_group.py,_run_multi_threaded,366,INFO,p9845,Successfully ingested row 2458 to 4916\n",
      "2022-07-22 20:55:26,075,feature_group.py,_run_multi_threaded,366,INFO,p9845,Successfully ingested row 14748 to 17206\n",
      "2022-07-22 20:55:26,129,feature_group.py,_run_multi_threaded,366,INFO,p9845,Successfully ingested row 12290 to 14748\n",
      "2022-07-22 20:55:26,590,feature_group.py,_run_multi_threaded,366,INFO,p9845,Successfully ingested row 9832 to 12290\n",
      "2022-07-22 20:55:27,525,feature_group.py,_run_multi_threaded,366,INFO,p9845,Successfully ingested row 17206 to 19658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='expedia-customer-inputs-2022-7-22-20-31', sagemaker_fs_runtime_client_config=<botocore.config.Config object at 0x7f0d02fa19e8>, max_workers=8, max_processes=1, profile_name=None, _async_result=<multiprocess.pool.MapResult object at 0x7f0ce0133cf8>, _processing_pool=<pool ProcessPool(ncpus=1)>, _failed_indices=[])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ingest features into the feature group\n",
    "# actually batch ingest the data into the feature store now\n",
    "logger.info(f\"about to begin ingestion of data into feature store, max_workers={MAX_WORKERS}\")\n",
    "feature_group.ingest(\n",
    "    data_frame=df_customer_inputs, max_workers=MAX_WORKERS, wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f50e46",
   "metadata": {},
   "source": [
    "## Query ingested data from the \"Online\" feature store\n",
    "This should immediately return the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56a806ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f2440d67-0198-4a93-b01a-f18cae5b7f91',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f2440d67-0198-4a93-b01a-f18cae5b7f91',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '3348',\n",
       "   'date': 'Fri, 22 Jul 2022 20:55:27 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Records': [{'FeatureGroupName': 'expedia-customer-inputs-2022-7-22-20-31',\n",
       "   'RecordIdentifierValueAsString': '81063',\n",
       "   'Record': [{'FeatureName': 'date_time',\n",
       "     'ValueAsString': '2014-07-15T15:18:15Z'},\n",
       "    {'FeatureName': 'site_name', 'ValueAsString': '13'},\n",
       "    {'FeatureName': 'posa_continent', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'user_location_country', 'ValueAsString': '46'},\n",
       "    {'FeatureName': 'user_location_region', 'ValueAsString': '172'},\n",
       "    {'FeatureName': 'user_location_city', 'ValueAsString': '56153'},\n",
       "    {'FeatureName': 'orig_destination_distance', 'ValueAsString': '434.5677'},\n",
       "    {'FeatureName': 'user_id', 'ValueAsString': '81063'},\n",
       "    {'FeatureName': 'is_mobile', 'ValueAsString': '0'},\n",
       "    {'FeatureName': 'is_package', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'channel', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'srch_ci', 'ValueAsString': '2014-08-25'},\n",
       "    {'FeatureName': 'srch_co', 'ValueAsString': '2014-08-31'},\n",
       "    {'FeatureName': 'srch_adults_cnt', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'srch_children_cnt', 'ValueAsString': '0'},\n",
       "    {'FeatureName': 'srch_rm_cnt', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'srch_destination_id', 'ValueAsString': '8746'},\n",
       "    {'FeatureName': 'srch_destination_type_id', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'is_booking', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'cnt', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'hotel_continent', 'ValueAsString': '6'},\n",
       "    {'FeatureName': 'hotel_country', 'ValueAsString': '105'},\n",
       "    {'FeatureName': 'hotel_market', 'ValueAsString': '29'},\n",
       "    {'FeatureName': 'hotel_cluster', 'ValueAsString': '25'},\n",
       "    {'FeatureName': 'duration', 'ValueAsString': '6.0'},\n",
       "    {'FeatureName': 'days_to_trip', 'ValueAsString': '40.0'},\n",
       "    {'FeatureName': 'start_of_trip_weekend', 'ValueAsString': '0'},\n",
       "    {'FeatureName': 'end_of_trip_weekend', 'ValueAsString': '1'}]},\n",
       "  {'FeatureGroupName': 'expedia-customer-inputs-2022-7-22-20-31',\n",
       "   'RecordIdentifierValueAsString': '50191',\n",
       "   'Record': [{'FeatureName': 'date_time',\n",
       "     'ValueAsString': '2013-06-19T19:29:59Z'},\n",
       "    {'FeatureName': 'site_name', 'ValueAsString': '2'},\n",
       "    {'FeatureName': 'posa_continent', 'ValueAsString': '3'},\n",
       "    {'FeatureName': 'user_location_country', 'ValueAsString': '66'},\n",
       "    {'FeatureName': 'user_location_region', 'ValueAsString': '174'},\n",
       "    {'FeatureName': 'user_location_city', 'ValueAsString': '5938'},\n",
       "    {'FeatureName': 'orig_destination_distance', 'ValueAsString': '376.4987'},\n",
       "    {'FeatureName': 'user_id', 'ValueAsString': '50191'},\n",
       "    {'FeatureName': 'is_mobile', 'ValueAsString': '0'},\n",
       "    {'FeatureName': 'is_package', 'ValueAsString': '0'},\n",
       "    {'FeatureName': 'channel', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'srch_ci', 'ValueAsString': '2013-06-21'},\n",
       "    {'FeatureName': 'srch_co', 'ValueAsString': '2013-06-23'},\n",
       "    {'FeatureName': 'srch_adults_cnt', 'ValueAsString': '2'},\n",
       "    {'FeatureName': 'srch_children_cnt', 'ValueAsString': '2'},\n",
       "    {'FeatureName': 'srch_rm_cnt', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'srch_destination_id', 'ValueAsString': '8834'},\n",
       "    {'FeatureName': 'srch_destination_type_id', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'is_booking', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'cnt', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'hotel_continent', 'ValueAsString': '2'},\n",
       "    {'FeatureName': 'hotel_country', 'ValueAsString': '50'},\n",
       "    {'FeatureName': 'hotel_market', 'ValueAsString': '355'},\n",
       "    {'FeatureName': 'hotel_cluster', 'ValueAsString': '25'},\n",
       "    {'FeatureName': 'duration', 'ValueAsString': '2.0'},\n",
       "    {'FeatureName': 'days_to_trip', 'ValueAsString': '1.0'},\n",
       "    {'FeatureName': 'start_of_trip_weekend', 'ValueAsString': '0'},\n",
       "    {'FeatureName': 'end_of_trip_weekend', 'ValueAsString': '1'}]}],\n",
       " 'Errors': [],\n",
       " 'UnprocessedIdentifiers': []}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use batch-get_record\n",
    "record_identifier_values = list((df_customer_inputs.user_id.unique()))[:2]\n",
    "response=featurestore_runtime.batch_get_record(\n",
    "    Identifiers=[\n",
    "        {\"FeatureGroupName\": customer_inputs_fg_name, \"RecordIdentifiersValueAsString\": record_identifier_values}\n",
    "    ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18b342",
   "metadata": {},
   "source": [
    "## Query ingested data from the \"Offline\" feature store\n",
    "The offline featrure store is queried using Athena. The feature store object has an Athena query method that is used to construct a query.\n",
    "\n",
    "**Note:** It could be several minutes (upto 15) until the data is ingested and available for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "763d79f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:55:27,950,<ipython-input-49-402cfdbf5394>,<module>,7,INFO,p27363,Athena table -> fg_table=expedia-customer-inputs-2022-7-22-20-31-1658523254\n"
     ]
    }
   ],
   "source": [
    "# add a 1 minute sleep to wait for at least some data to show up in the offline feature store\n",
    "# time.sleep(60)\n",
    "\n",
    "# the feature group provided a convenient Athena object to query the offline feature store data\n",
    "query = feature_group.athena_query()\n",
    "customers_fg_table = query.table_name\n",
    "logger.info(f\"Athena table -> fg_table={customers_fg_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "274c6755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:55:27,956,<ipython-input-50-7c31cd300965>,<module>,3,INFO,p27363,going to run this query -> SELECT * FROM \"expedia-customer-inputs-2022-7-22-20-31-1658523254\" limit 10 and store the results in s3://athena-query-results-eb4dbb00/expedia-customer-inputs-2022-7-22-20-31/query_results/\n",
      "2022-07-22 20:55:28,154,session.py,wait_for_athena_query,4118,INFO,p27363,Query 7ce67fac-3646-4ea1-aec9-6ba79b36702f is being executed.\n",
      "2022-07-22 20:55:33,205,session.py,wait_for_athena_query,4127,INFO,p27363,Query 7ce67fac-3646-4ea1-aec9-6ba79b36702f successfully executed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_to_trip</th>\n",
       "      <th>start_of_trip_weekend</th>\n",
       "      <th>end_of_trip_weekend</th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date_time, site_name, posa_continent, user_location_country, user_location_region, user_location_city, orig_destination_distance, user_id, is_mobile, is_package, channel, srch_ci, srch_co, srch_adults_cnt, srch_children_cnt, srch_rm_cnt, srch_destination_id, srch_destination_type_id, is_booking, cnt, hotel_continent, hotel_country, hotel_market, hotel_cluster, duration, days_to_trip, start_of_trip_weekend, end_of_trip_weekend, write_time, api_invocation_time, is_deleted]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = f'SELECT * FROM \"{customers_fg_table}\" limit 10'\n",
    "output_location=f's3://{athena_query_results_bucket_name}/{customer_inputs_fg_name}/query_results/'\n",
    "logger.info(f\"going to run this query -> {query_string} and store the results in {output_location}\")\n",
    "\n",
    "# run the query\n",
    "query.run(query_string=query_string, output_location=output_location)\n",
    "\n",
    "# wait for the results\n",
    "query.wait()\n",
    "df_fg = query.as_dataframe()\n",
    "\n",
    "# results\n",
    "df_fg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b91776",
   "metadata": {},
   "source": [
    "## Save variables for next stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "edfad193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:55:33,370,utils.py,write_param,116,INFO,p27363,write_param, fpath=../config/customer_inputs_fg_name, writing customer_inputs_fg_name=expedia-customer-inputs-2022-7-22-20-31\n",
      "2022-07-22 20:55:33,371,utils.py,write_param,116,INFO,p27363,write_param, fpath=../config/customer_inputs_fg_table, writing customer_inputs_fg_table=expedia-customer-inputs-2022-7-22-20-31-1658523254\n",
      "2022-07-22 20:55:33,372,utils.py,write_param,116,INFO,p27363,write_param, fpath=../config/customer_inputs_fg_query_string, writing customer_inputs_fg_query_string=SELECT * FROM \"expedia-customer-inputs-2022-7-22-20-31-1658523254\" limit 10\n"
     ]
    }
   ],
   "source": [
    "# write feature group names and query_string to a file, used when generating lineage\n",
    "utils.write_param(\"customer_inputs_fg_name\", customer_inputs_fg_name)\n",
    "utils.write_param(\"customer_inputs_fg_table\", customers_fg_table)\n",
    "utils.write_param(\"customer_inputs_fg_query_string\", query_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab775cb5",
   "metadata": {},
   "source": [
    "## Create feature group for the destination features\n",
    "We first do PCA on the destinations features to reduce it to 3 features and then store the principal components in a separate feature group of their own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "164eda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensions of destination folder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# the number of principal components to keep is just set to 3 here since this is a demo\n",
    "# but in an actual production model this would be determined by examining a scree plot/variance explained rule/other critiera\n",
    "pca = PCA(n_components=PC_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9edf6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns except the src_destination_id \n",
    "cols_to_use = [c for c in df_destinations.columns if c != 'srch_destination_id']\n",
    "destinations_pca = pca.fit_transform(df_destinations[cols_to_use])\n",
    "df_destinations_pca = pd.DataFrame(destinations_pca, columns=[f'pc{x}' for x in range(1, (PC_TO_KEEP+1))])\n",
    "\n",
    "# typecasting the destination id to string since this is going to be used as the record identifier in the feature store\n",
    "# which has to be a string\n",
    "df_destinations_pca[\"srch_destination_id\"] = df_destinations[\"srch_destination_id\"].astype('string')\n",
    "\n",
    "# since there is no date time associated with these features in the input dataset so just use the current datetime\n",
    "from datetime import datetime\n",
    "# datetime.utcnow().isoformat() will return something like '2022-06-07T22:08:19.399890', need to\n",
    "# trunchate it to yyyy-MM-dd'T'HH:mm:ss format to make it work with sagemaker feature store\n",
    "datetime_iso8601_now = f\"{datetime.utcnow().isoformat().split('.')[0]}Z\"\n",
    "df_destinations_pca[\"date_time\"] = datetime_iso8601_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c2cd3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.044268</td>\n",
       "      <td>0.169419</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-22T20:55:34Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440761</td>\n",
       "      <td>0.077405</td>\n",
       "      <td>-0.091572</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-22T20:55:34Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.020677</td>\n",
       "      <td>0.012107</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-07-22T20:55:34Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.480467</td>\n",
       "      <td>-0.040345</td>\n",
       "      <td>-0.019320</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-22T20:55:34Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.207253</td>\n",
       "      <td>-0.042694</td>\n",
       "      <td>-0.011744</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-07-22T20:55:34Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc1       pc2       pc3 srch_destination_id             date_time\n",
       "0 -0.044268  0.169419  0.032522                   0  2022-07-22T20:55:34Z\n",
       "1 -0.440761  0.077405 -0.091572                   1  2022-07-22T20:55:34Z\n",
       "2  0.001033  0.020677  0.012107                   2  2022-07-22T20:55:34Z\n",
       "3 -0.480467 -0.040345 -0.019320                   3  2022-07-22T20:55:34Z\n",
       "4 -0.207253 -0.042694 -0.011744                   4  2022-07-22T20:55:34Z"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_destinations_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7c8a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_destinations_pca['date_time'] = df_destinations_pca['date_time'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39f2fb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pc1                    float64\n",
       "pc2                    float64\n",
       "pc3                    float64\n",
       "srch_destination_id     string\n",
       "date_time               string\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_destinations_pca.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb686c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FeatureDefinition(feature_name='pc1', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='pc2', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='pc3', feature_type=<FeatureTypeEnum.FRACTIONAL: 'Fractional'>),\n",
       " FeatureDefinition(feature_name='srch_destination_id', feature_type=<FeatureTypeEnum.STRING: 'String'>),\n",
       " FeatureDefinition(feature_name='date_time', feature_type=<FeatureTypeEnum.STRING: 'String'>)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group = FeatureGroup(name=destinations_fg_name, sagemaker_session=feature_store_session)\n",
    "feature_group.load_feature_definitions(data_frame=df_destinations_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45b77f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:015469603702:feature-group/expedia-destinations-2022-7-22-20-31',\n",
       " 'ResponseMetadata': {'RequestId': '8aa8f2dd-52d7-4d6b-b5a0-202c26e97ad3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '8aa8f2dd-52d7-4d6b-b5a0-202c26e97ad3',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '113',\n",
       "   'date': 'Fri, 22 Jul 2022 20:55:34 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.create(\n",
    "    s3_uri=f\"s3://{feature_store_bucket_name}/{customer_inputs_fg_name}\",\n",
    "    record_identifier_name=\"srch_destination_id\",\n",
    "    event_time_feature_name=\"date_time\",\n",
    "    role_arn=role,\n",
    "    enable_online_store=True,\n",
    "    tags=[{'Key':'AppName','Value':app_name}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdc46155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:55:34,836,utils.py,check_feature_group_status,99,INFO,p27363,Waiting for Feature Group to be Created\n",
      "2022-07-22 20:55:39,897,utils.py,check_feature_group_status,99,INFO,p27363,Waiting for Feature Group to be Created\n",
      "2022-07-22 20:55:44,953,utils.py,check_feature_group_status,99,INFO,p27363,Waiting for Feature Group to be Created\n",
      "2022-07-22 20:55:50,012,utils.py,check_feature_group_status,99,INFO,p27363,Waiting for Feature Group to be Created\n",
      "2022-07-22 20:55:55,082,utils.py,check_feature_group_status,102,INFO,p27363,FeatureGroup expedia-destinations-2022-7-22-20-31 successfully created.\n"
     ]
    }
   ],
   "source": [
    "utils.check_feature_group_status(feature_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34f209d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:55:55,087,<ipython-input-60-abca2e197c58>,<module>,3,INFO,p27363,about to begin ingestion of data into feature store, max_workers=8\n",
      "2022-07-22 20:55:57,206,feature_group.py,_ingest_single_batch,211,INFO,p10714,Started ingesting index 23292 to 31056\n",
      "2022-07-22 20:55:57,236,feature_group.py,_ingest_single_batch,211,INFO,p10714,Started ingesting index 38820 to 46584\n",
      "2022-07-22 20:55:57,270,feature_group.py,_ingest_single_batch,211,INFO,p10714,Started ingesting index 46584 to 54348\n",
      "2022-07-22 20:55:57,274,feature_group.py,_ingest_single_batch,211,INFO,p10714,Started ingesting index 31056 to 38820\n",
      "2022-07-22 20:55:57,285,feature_group.py,_ingest_single_batch,211,INFO,p10714,Started ingesting index 7764 to 15528\n",
      "2022-07-22 20:55:57,303,feature_group.py,_ingest_single_batch,211,INFO,p10714,Started ingesting index 54348 to 62106\n",
      "2022-07-22 20:55:57,314,feature_group.py,_ingest_single_batch,211,INFO,p10714,Started ingesting index 15528 to 23292\n",
      "2022-07-22 20:55:57,327,feature_group.py,_ingest_single_batch,211,INFO,p10714,Started ingesting index 0 to 7764\n",
      "2022-07-22 20:58:00,377,feature_group.py,_run_multi_threaded,366,INFO,p10714,Successfully ingested row 23292 to 31056\n",
      "2022-07-22 20:58:01,163,feature_group.py,_run_multi_threaded,366,INFO,p10714,Successfully ingested row 7764 to 15528\n",
      "2022-07-22 20:58:01,188,feature_group.py,_run_multi_threaded,366,INFO,p10714,Successfully ingested row 38820 to 46584\n",
      "2022-07-22 20:58:01,835,feature_group.py,_run_multi_threaded,366,INFO,p10714,Successfully ingested row 31056 to 38820\n",
      "2022-07-22 20:58:02,832,feature_group.py,_run_multi_threaded,366,INFO,p10714,Successfully ingested row 46584 to 54348\n",
      "2022-07-22 20:58:03,343,feature_group.py,_run_multi_threaded,366,INFO,p10714,Successfully ingested row 0 to 7764\n",
      "2022-07-22 20:58:03,621,feature_group.py,_run_multi_threaded,366,INFO,p10714,Successfully ingested row 15528 to 23292\n",
      "2022-07-22 20:58:04,138,feature_group.py,_run_multi_threaded,366,INFO,p10714,Successfully ingested row 54348 to 62106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='expedia-destinations-2022-7-22-20-31', sagemaker_fs_runtime_client_config=<botocore.config.Config object at 0x7f0d02fa19e8>, max_workers=8, max_processes=1, profile_name=None, _async_result=<multiprocess.pool.MapResult object at 0x7f0d0352e3c8>, _processing_pool=<pool ProcessPool(ncpus=1)>, _failed_indices=[])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ingest features into the feature group\n",
    "# actually batch ingest the data into the feature store now\n",
    "logger.info(f\"about to begin ingestion of data into feature store, max_workers={MAX_WORKERS}\")\n",
    "feature_group.ingest(\n",
    "    data_frame=df_destinations_pca, max_workers=MAX_WORKERS, wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "284c1b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'bb643707-30fb-4710-b931-f4dd6d7c3e1f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'bb643707-30fb-4710-b931-f4dd6d7c3e1f',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '878',\n",
       "   'date': 'Fri, 22 Jul 2022 20:58:04 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Records': [{'FeatureGroupName': 'expedia-destinations-2022-7-22-20-31',\n",
       "   'RecordIdentifierValueAsString': '0',\n",
       "   'Record': [{'FeatureName': 'pc1', 'ValueAsString': '-0.04426762797342786'},\n",
       "    {'FeatureName': 'pc2', 'ValueAsString': '0.169419364576512'},\n",
       "    {'FeatureName': 'pc3', 'ValueAsString': '0.03252220673796825'},\n",
       "    {'FeatureName': 'srch_destination_id', 'ValueAsString': '0'},\n",
       "    {'FeatureName': 'date_time', 'ValueAsString': '2022-07-22T20:55:34Z'}]},\n",
       "  {'FeatureGroupName': 'expedia-destinations-2022-7-22-20-31',\n",
       "   'RecordIdentifierValueAsString': '1',\n",
       "   'Record': [{'FeatureName': 'pc1', 'ValueAsString': '-0.44076100320199924'},\n",
       "    {'FeatureName': 'pc2', 'ValueAsString': '0.07740481644871261'},\n",
       "    {'FeatureName': 'pc3', 'ValueAsString': '-0.09157177113958112'},\n",
       "    {'FeatureName': 'srch_destination_id', 'ValueAsString': '1'},\n",
       "    {'FeatureName': 'date_time', 'ValueAsString': '2022-07-22T20:55:34Z'}]}],\n",
       " 'Errors': [],\n",
       " 'UnprocessedIdentifiers': []}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use batch-get_record\n",
    "record_identifier_values = list((df_destinations_pca.srch_destination_id.unique()))[:2]\n",
    "response=featurestore_runtime.batch_get_record(\n",
    "    Identifiers=[\n",
    "        {\"FeatureGroupName\": destinations_fg_name, \"RecordIdentifiersValueAsString\": record_identifier_values}\n",
    "    ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3997fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:58:04,714,<ipython-input-62-3b4fd3e5966a>,<module>,7,INFO,p27363,Athena table -> fg_table=expedia-destinations-2022-7-22-20-31-1658523334\n"
     ]
    }
   ],
   "source": [
    "# add a 1 minute sleep to wait for at least some data to show up in the offline feature store\n",
    "# time.sleep(60)\n",
    "\n",
    "# the feature group provided a convenient Athena object to query the offline feature store data\n",
    "query = feature_group.athena_query()\n",
    "destinations_fg_table = query.table_name\n",
    "logger.info(f\"Athena table -> fg_table={destinations_fg_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac59a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:58:04,721,utils.py,write_param,116,INFO,p27363,write_param, fpath=../config/destinations_fg_table, writing destinations_fg_table=expedia-destinations-2022-7-22-20-31-1658523334\n",
      "2022-07-22 20:58:04,722,<ipython-input-63-fa8da0ead993>,<module>,4,INFO,p27363,going to run this query -> SELECT * FROM \"expedia-destinations-2022-7-22-20-31-1658523334\" limit 10 and store the results in s3://athena-query-results-eb4dbb00/expedia-destinations-2022-7-22-20-31/query_results/\n",
      "2022-07-22 20:58:04,882,session.py,wait_for_athena_query,4118,INFO,p27363,Query f67a1314-6da8-4712-aaa0-941891401643 is being executed.\n",
      "2022-07-22 20:58:09,951,session.py,wait_for_athena_query,4127,INFO,p27363,Query f67a1314-6da8-4712-aaa0-941891401643 successfully executed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pc1, pc2, pc3, srch_destination_id, date_time, write_time, api_invocation_time, is_deleted]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = f'SELECT * FROM \"{destinations_fg_table}\" limit 10'\n",
    "utils.write_param(\"destinations_fg_table\", destinations_fg_table)\n",
    "output_location=f's3://{athena_query_results_bucket_name}/{destinations_fg_name}/query_results/'\n",
    "logger.info(f\"going to run this query -> {query_string} and store the results in {output_location}\")\n",
    "\n",
    "# run the query\n",
    "query.run(query_string=query_string, output_location=output_location)\n",
    "\n",
    "# wait for the results\n",
    "query.wait()\n",
    "df_fg = query.as_dataframe()\n",
    "\n",
    "# results\n",
    "df_fg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2df8e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:58:10,121,utils.py,write_param,116,INFO,p27363,write_param, fpath=../config/destinations_fg_name, writing destinations_fg_name=expedia-destinations-2022-7-22-20-31\n"
     ]
    }
   ],
   "source": [
    "# write feature group name to a file\n",
    "utils.write_param(\"destinations_fg_name\", destinations_fg_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1099557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
