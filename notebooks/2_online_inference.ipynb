{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7b8d61",
   "metadata": {},
   "source": [
    "# Online Inference\n",
    "\n",
    "This notebook simulates an online inference pipeline by publishing data to a Kinesis stream which is picked up by an associated Lambda function and this Lambda function joins this data with additional data from an online feature store and then invokes a SageMaker endpoint to get inference in real-time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import logging\n",
    "import boto3\n",
    "import json\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8304af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from a different path\n",
    "path = Path(os.path.abspath(os.getcwd()))\n",
    "package_dir = f'{str(path.parent)}/utils'\n",
    "print(package_dir)\n",
    "sys.path.insert(0, package_dir)\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722566ec",
   "metadata": {},
   "source": [
    "## Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('__name__')\n",
    "logging.basicConfig(format=\"%(asctime)s,%(filename)s,%(funcName)s,%(lineno)s,%(levelname)s,p%(process)s,%(message)s\", level=logging.INFO)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6994d4c",
   "metadata": {},
   "source": [
    "## Global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "STACK_NAME = \"expedia-feature-store-demo-v2\"\n",
    "LOCAL_DATA_DIR = \"../data\"\n",
    "DESTINATION_FEATURES = \"pc1,pc2,pc3\"\n",
    "PREDICTED_VARIABLE = \"hotel_cluster_predicted\"\n",
    "RECORDS_TO_STREAM = 5\n",
    "PK = 'user_id' # partition key for kinesis stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d30f6",
   "metadata": {},
   "source": [
    "## Setup config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read output variables from cloud formation stack, these will be used as parameters throughout\n",
    "# the code\n",
    "data_bucket_name = utils.get_cfn_stack_outputs(STACK_NAME, 'DataBucketName')\n",
    "model_bucket_name = utils.get_cfn_stack_outputs(STACK_NAME, 'MLModelBucketName')\n",
    "athena_query_results_bucket_name = utils.get_cfn_stack_outputs(STACK_NAME, 'AthenaQueryResultsBucketName')\n",
    "feature_store_bucket_name = utils.get_cfn_stack_outputs(STACK_NAME, 'FeatureStoreBucketName')\n",
    "hotel_cluster_prediction_fn_arn = utils.get_cfn_stack_outputs(STACK_NAME, 'HotelClusterPredictionFunction')\n",
    "hotel_cluster_prediction_ddb_table_name = utils.get_cfn_stack_outputs(STACK_NAME, 'HotelClusterPredictionsTableName')\n",
    "\n",
    "logger.info(f\"data_bucket_name={data_bucket_name},\\nathena_query_results_bucket_name={athena_query_results_bucket_name},\\n\"\n",
    "            f\"model_bucket_name={model_bucket_name}\\nfeature_store_bucket_name={feature_store_bucket_name},\\n\"\n",
    "            f\"hotel_cluster_prediction_fn_arn={hotel_cluster_prediction_fn_arn}\\nhotel_cluster_prediction_ddb_table_name={hotel_cluster_prediction_ddb_table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read outputs from previous notebooks that are needed by this notebook.\n",
    "# these are available as local files.\n",
    "customer_inputs_fg_name = utils.read_param(\"customer_inputs_fg_name\")\n",
    "destinations_fg_name = utils.read_param(\"destinations_fg_name\")\n",
    "customer_inputs_fg_table = utils.read_param(\"customer_inputs_fg_table\")\n",
    "destinations_fg_table = utils.read_param(\"destinations_fg_table\")\n",
    "customer_inputs_fg_name = utils.read_param(\"customer_inputs_fg_name\")\n",
    "ml_model_endpoint_name = utils.read_param(\"endpoint_name\")\n",
    "\n",
    "# read params from the cloud formation stack\n",
    "raw_data_dir = utils.get_cfn_stack_parameters(STACK_NAME, 'RawDataDir')\n",
    "app_name = utils.get_cfn_stack_parameters(STACK_NAME, 'AppName')\n",
    "\n",
    "training_dataset_fname = utils.get_cfn_stack_parameters(STACK_NAME, 'TrainingDatasetFileName')\n",
    "test_dataset_fname = utils.get_cfn_stack_parameters(STACK_NAME, 'TestDatasetFileName')\n",
    "validation_dataset_fname = utils.get_cfn_stack_parameters(STACK_NAME, 'ValidationDatasetFileName')\n",
    "\n",
    "training_job_instance_type = utils.get_cfn_stack_parameters(STACK_NAME, 'TrainingJobInstanceType')\n",
    "if training_job_instance_type is None:\n",
    "    training_job_instance_type = \"ml.m5.xlarge\"\n",
    "training_job_instance_count = int(utils.get_cfn_stack_parameters(STACK_NAME, 'TrainingJobNodeInstanceCount'))\n",
    "\n",
    "model_ep_instance_type = utils.get_cfn_stack_parameters(STACK_NAME, 'ModelEndpointInstanceType')\n",
    "model_ep_instance_count = int(utils.get_cfn_stack_parameters(STACK_NAME, 'ModelEndpointInstanceCount'))\n",
    "\n",
    "customer_input_stream_name = utils.get_cfn_stack_parameters(STACK_NAME, 'CustomerInputStreamName')\n",
    "            \n",
    "logger.info(f\"customer_inputs_fg_table={customer_inputs_fg_table},\\ndestinations_fg_table={destinations_fg_table},\\n\"\n",
    "            f\"customer_inputs_fg_name={customer_inputs_fg_name},\\ndestinations_fg_name={destinations_fg_name}\\n\"\n",
    "            f\"raw_data_dir={raw_data_dir},\\ntraining_dataset_fname={training_dataset_fname},\\n\"\n",
    "            f\"test_dataset_fname={test_dataset_fname},\\nvalidation_dataset_fname=-{validation_dataset_fname}\\n\"\n",
    "            f\"training_job_instance_type={training_job_instance_type},\\ntraining_job_instance_count={training_job_instance_count},\\n\"\n",
    "            f\"model_ep_instance_type={model_ep_instance_type},\\nmodel_ep_instance_count={model_ep_instance_count},\\ncustomer_input_stream_name={customer_input_stream_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42e40d",
   "metadata": {},
   "source": [
    "## Update the lambda function\n",
    "\n",
    "The lambda function handler for the Kinesis stream needs to be updated with the SageMaker endpoint name (this name was not available at the time of deploying the Lambda via the cloud formation template)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clients for the services we are going to use\n",
    "lambda_client = boto3.client('lambda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ad016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the environment variables for the lambda as a mechanism for passing config values. \n",
    "# Sagemaker endpoint name, the destinations feature group name etc are all available \n",
    "# as variables in this notebook (read already from local files). In a production environment\n",
    "# these would be read from Parameter Store.\n",
    "\n",
    "logger.info(f'updating Lambda function with ARN={hotel_cluster_prediction_fn_arn} to use ML model endpoint: {ml_model_endpoint_name}')\n",
    "variables = lambda_client.get_function_configuration(FunctionName=hotel_cluster_prediction_fn_arn)['Environment']['Variables']\n",
    "variables['ENDPOINT_NAME'] = ml_model_endpoint_name\n",
    "variables['FG_NAME'] = destinations_fg_name\n",
    "variables['DDB_TABLE_NAME'] = hotel_cluster_prediction_ddb_table_name\n",
    "variables['ONLINE_FEATURE_GROUP_KEY'] = 'srch_destination_id'\n",
    "variables['ONLINE_FEATURE_GROUP_FEATURES_OF_INTEREST'] = DESTINATION_FEATURES\n",
    "variables['PREDICTED_VARIABLE'] = PREDICTED_VARIABLE\n",
    "\n",
    "resp = lambda_client.update_function_configuration(\n",
    "    FunctionName=hotel_cluster_prediction_fn_arn,\n",
    "      Environment={\n",
    "        'Variables': variables\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a73b9",
   "metadata": {},
   "source": [
    "## Stream test data\n",
    "At this point we are all set to stream test data on the Kinesis data stream. This test data is available in a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data from local file\n",
    "fpath = os.path.join(LOCAL_DATA_DIR, test_dataset_fname)\n",
    "df = pd.read_csv(fpath)\n",
    "logger.info(f\"read test data from {fpath}, dataframe shape is {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the first record just for debug purposes\n",
    "record = json.loads(df.to_json(orient='records'))[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream each row of the dataframe as a json to the Kinesis data stream\n",
    "kinesis_client = boto3.client('kinesis')\n",
    "\n",
    "for record in json.loads(df.to_json(orient='records'))[:RECORDS_TO_STREAM]:\n",
    "    data = json.dumps(record)\n",
    "    logger.info(f\"Sending data, record.{PK}={record[PK]}...\")\n",
    "    response = kinesis_client.put_record(StreamName = customer_input_stream_name,\n",
    "                                         Data = data,\n",
    "                                         PartitionKey = PK)\n",
    "\n",
    "    if (response['ResponseMetadata']['HTTPStatusCode'] != 200):\n",
    "        logger.error(\"ERROR: Kinesis put_record failed: \\n{}\".format(json.dumps(response)))\n",
    "    else:\n",
    "        logger.info(\"data sent successfully...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e0fb4b",
   "metadata": {},
   "source": [
    "## Check the DynamoDB table\n",
    "\n",
    "Now check the DynamoDB table (ExpediaPerCustomerHotelClusterPredictionsunless changed when deploying the Cloud Formation template) for new data inserted corresponding to the records streamed in the previous step. Look for the hotel_cluster_predicted field, this field contains the prediction from the SageMaker model endpoint.\n",
    "\n",
    "Also check the logs of the Lambda function to see that it got invokes for every record put on the Kinesis stream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6d86a",
   "metadata": {},
   "source": [
    "<img src=\"../images/ddb_table.png\">Data Profile</img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
